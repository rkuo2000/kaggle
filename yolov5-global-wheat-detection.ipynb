{"cells":[{"metadata":{},"cell_type":"markdown","source":"# YoloV5 for Global Wheat Detection"},{"metadata":{},"cell_type":"markdown","source":"## Competition Dataset : [Global Wheat Detection](https://www.kaggle.com/c/global-wheat-detection)\n## Config: [configyolo5](https://www.kaggle.com/orkatz2/configyolo5) "},{"metadata":{},"cell_type":"markdown","source":"## Repro YoloV5 (v3.0)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5\n!mv yolov5/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m pip install --upgrade pip\n!pip install -r requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train from scratch don't need the pretrained models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Download YoloV5 pretrained models\n#!weights/download_weights.sh","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### convert Train Label"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/global-wheat-detection/train.csv')\nbboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    df[column] = bboxs[:,i]\ndf.drop(columns=['bbox'], inplace=True)\ndf['x_center'] = df['x'] + df['w']/2\ndf['y_center'] = df['y'] + df['h']/2\ndf['classes'] = 0\nfrom tqdm.auto import tqdm\nimport shutil as sh\ndf = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = list(set(df.image_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = 'train'\nif True:\n    for fold in [0]:\n        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n        for name,mini in tqdm(df.groupby('image_id')):\n            if name in val_index:\n                path2save = 'val2017/'\n            else:\n                path2save = 'train2017/'\n            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n                row = row/1024\n                row = row.astype(str)\n                for j in range(len(row)):\n                    text = ' '.join(row[j])\n                    f.write(text)\n                    f.write(\"\\n\")\n            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n            sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{},"cell_type":"markdown","source":"train 1 epoch takes ~15 mins using GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Model\n!python train.py --img 1024 --batch 2 --epochs 1 --data ../input/configyolo5/wheat0.yaml --cfg models/yolov5x.yaml --weight \"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model saved at runs/exp0/weights/best.pt"},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy saved model to weights folder\n!cp runs/exp0/weights/best.pt weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove convertor of training data\n!rm -rf convertor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Model"},{"metadata":{},"cell_type":"markdown","source":"10 test images in '../input/global-wheat-detection/test/'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect Test Images\n!python detect.py --source '../input/global-wheat-detection/test/' --weight weights/best.pt --output 'inference/output' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"output images in 'inference/output'"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l inference/output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display Output Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, clear_output  # to display images\nImage(filename='inference/output/2fd875eaa.jpg', width=600)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}