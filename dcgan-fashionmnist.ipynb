{"cells":[{"metadata":{"id":"AY-qM-4swLUb"},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"id":"bhqrEV6hkFC3","trusted":false},"cell_type":"code","source":"# Importing Keras via TensorFlow\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom IPython import display\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"bRT9FVAdwUDP"},"cell_type":"markdown","source":"## Load and Visualize the data"},{"metadata":{"id":"9g2aKYa9kG1Q","outputId":"2950ae16-f975-42a8-b559-30c82769bf5c","trusted":false},"cell_type":"code","source":"# Loading data from Fashion MNIST dataset (available as built-in database in tf.keras)\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{"id":"PIyO0h8fB6mu","trusted":false},"cell_type":"code","source":"# Normalizing training dataset\nx_train = x_train.astype(np.float32)/255.0","execution_count":null,"outputs":[]},{"metadata":{"id":"UFEwYL2HJ5no","outputId":"d3306dd6-909f-4219-f9a1-c4af0fc0feff","trusted":false},"cell_type":"code","source":"# Fixing plot size for 4x4 matrix of images\nplt.figure(figsize=(8,8))\n# Plotting 16 random training images as 4x4 matrix\nfor i in range(16) :\n    plt.subplot(4, 4, i+1)\n    # cmap - maps numbers to colours based on colormap specified - Here Binary colormap is used\n    plt.imshow(x_train[i], cmap = plt.cm.binary)\n    # X and Y ticks are set empty\n    plt.xticks([])\n    plt.yticks([])\n# Display the plot in console\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_B6mV5YZw_p7"},"cell_type":"markdown","source":"## Splitting training data into batches"},{"metadata":{"id":"oqwFFyrFkG7b","outputId":"62da848d-73e6-428e-9d48-0eed933e6e38","trusted":false},"cell_type":"code","source":"# Reshaping to match with dims of generated image from noise \nx_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1.\nprint(x_train_dcgan.shape)\n\n# 32 images will be grouped as one batch from training dataset\nbatch_size = 32\n# from_tensor_slices - creates dataset with seperate element for each row\n# from_tensors - combines the input and returns dataset as single element\n\n# shuffle - Randomly sample from input - can hold items of buffersize mentioned\n    # An item is randomly picked from 1000 items in buffer and next item from source dataset will be loaded into buffer\ndataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan).shuffle(1000)\n# Last (Incomplete) batch removed\n# When a data is being processed, next data is fetched from dataset synchronously - Reduces time\ndataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)","execution_count":null,"outputs":[]},{"metadata":{"id":"w5qOeWQDxp7A"},"cell_type":"markdown","source":"## Build the Generator Network for DCGAN"},{"metadata":{"id":"E_Pz36D9T3dp","trusted":false},"cell_type":"code","source":"num_features = 100\n\n# Creating Generator Neural Network\ngenerator = keras.models.Sequential([\n    # If dense layer is first layer of model, need to specify input shape. else, should not\n    keras.layers.Dense(7*7*128, input_shape = [num_features]),\n    # Reshaping to make sure size is as required\n    keras.layers.Reshape([7,7,128]),\n    # Performing Batch Normalization for easing out computations\n    keras.layers.BatchNormalization(),\n    \n    # Performing Transpose convolution to convert small input(noise) to larger input(image)\n        # selu (Scaled Exponential Linear Unit) activation is more efficient for GANs\n        # 'same' padding tries to pad data in balanced fashion on either sides\n        # Convolution layers perform the core operation involving features\n    \n    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding = 'same', activation = 'selu'),\n    # Performing Batch Normalization for easing out computations\n    keras.layers.BatchNormalization(),\n    \n    # Performing Transpose convolution at final layer - tanh activation used in final layer\n    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding = 'same', activation = 'tanh' )\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"rMUiBeXhVMWf"},"cell_type":"markdown","source":"## Build the Discriminator Network for DCGAN"},{"metadata":{"id":"LNoA-K62kHEI","trusted":false},"cell_type":"code","source":"# Creating Discriminator Neural Network\ndiscriminator = keras.models.Sequential([\n    keras.layers.Conv2D(64, (5,5), (2,2), padding = 'same', input_shape = [28,28,1]),\n    keras.layers.LeakyReLU(0.2), # Activation function\n    keras.layers.Dropout(0.3), # Dropping 30 percent of neurons to acoid overfit\n    \n    keras.layers.Conv2D(128, (5,5), (2,2), padding = 'same'),\n    keras.layers.LeakyReLU(0.2), # Activation function\n    keras.layers.Dropout(0.3), # Dropping 30 percent of neurons to acoid overfit   \n    \n    keras.layers.Flatten(), # Flatten the layer to feed into final layer\n    # Since discriminator performs binary classification, sigmoid activation is used in final layer\n    keras.layers.Dense(1, activation = 'sigmoid')   \n])\n\n# Compiling Discriminator\ndiscriminator.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop')\n# First we need to train only generator\ndiscriminator.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"id":"gjkSFNGGVT4I"},"cell_type":"markdown","source":"## Compile DCGAN"},{"metadata":{"id":"DOpPAq_ckHHz","trusted":false},"cell_type":"code","source":"# Creating and compiling GAN\ngan = keras.models.Sequential([generator, discriminator])\ngan.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop')","execution_count":null,"outputs":[]},{"metadata":{"id":"nKJzwn3ExORM"},"cell_type":"markdown","source":"## Training procedure for DCGAN"},{"metadata":{"id":"Ic76LI4xfGPD","trusted":false},"cell_type":"code","source":"# Generating random noise to serve as test_noise_input for Generator model\nseed = tf.random.normal(shape = [batch_size, num_features])","execution_count":null,"outputs":[]},{"metadata":{"id":"RX-t-8XmlemS","trusted":false},"cell_type":"code","source":"# Defining function to train GAN\ndef train_dcgan(gan, dataset, batch_size, num_features, total_epochs = 10):\n    # Getting generator and discriminator from GAN\n    generator, discriminator = gan.layers\n    for epoch in tqdm(range(total_epochs)):\n        print(\"Epoch {} out of {} epochs\" .format(epoch+1, total_epochs))\n        for x_batch in dataset:\n            # For each epoch, \n                # For each batch in dataset\n                    #random noise is converted into a realistic Fashion MNIST image using trained generator\n            noise = tf.random.normal(shape = [batch_size, num_features])\n            generated_images = generator(noise)\n            # \"Realistic\" and \"Real\" images are concatenated for to be fed as input to discriminator\n            disc_input = tf.concat([generated_images, x_batch], axis = 0)\n            # Training discriminator on current batch\n                # Creating output labels for discriminator\n            disc_labels = tf.constant( [[0.]]*batch_size + [[1.]]*batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(disc_input, disc_labels)\n            # Training generator on current batch\n                # Creating output labels for generator\n            gen_labels = tf.constant( [[1.]]*batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, gen_labels)\n        # To clear previous output (if new output is available to be replaced)\n        display.clear_output(wait = True)\n        # Calling custom function to display the generated images at the end of every epoch\n        generate_images(generator, epoch+1, seed)\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"id":"NDbSHgN5gVT0","trusted":false},"cell_type":"code","source":"# Custom function to display the generated images\ndef generate_images(model, epoch, test_input):\n    # training = False -> Evaluation mode\n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(10,10))\n    \n    for i in range(25):\n        plt.subplot(5, 5, i+1)\n        # Converting prediction to the scale of 0-255\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n        plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"WIttFRtEkHKA","outputId":"8b29129f-7e80-4d87-98e7-e69183fe395c","trusted":false},"cell_type":"code","source":"# Calling the GAN training function\ntrain_dcgan(gan, dataset, batch_size, num_features, total_epochs = 20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}