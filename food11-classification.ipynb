{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Food-11 Classification"},{"metadata":{},"cell_type":"markdown","source":"## using EfficientNet B7"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input/food11-image-dataset'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = '../input/food11-image-dataset/training'\nvalid_dir = '../input/food11-image-dataset/validation'\ntest_dir  = '../input/food11-image-dataset/evaluation'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirNames = os.listdir(train_dir)\n\nfor dirName in dirNames:\n    if '.txt' in dirName:\n        print(dirName)\n        dirNames.remove(dirName)\n\n\nprint(dirNames)\nprint(len(dirNames))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = dirNames.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainFiles = []\ntrainClasses = []\n\nfor dirName in dirNames:\n    for file in os.listdir(train_dir+\"/\"+dirName):\n        trainFiles.append(train_dir+\"/\"+dirName+\"/\"+file)\n        trainClasses.append(dirName)\n\nprint(len(trainFiles), len(trainClasses))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### display image of a training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.imshow(mpimg.imread(trainFiles[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Equilibre "},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\ndef plot_equilibre(categories, counts):\n\n    plt.figure(figsize=(12, 8))\n\n    sns_bar = sns.barplot(x=categories, y=counts)\n    sns_bar.set_xticklabels(categories, rotation=45)\n    plt.title('Equilibre of Training Dataset')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = dirNames\ncounts = []\n[counts.append(trainClasses.count(dirName)) for dirName in dirNames]\n\nplot_equilibre(categories, counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_size=(224,224)\nbatch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',    \n    shuffle=True,\n    seed=42,\n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = ImageDataGenerator(rescale=1./255)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    valid_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Input, BatchNormalization, Activation, LeakyReLU, Concatenate\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install -q efficientnet\n#import efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 11\ninput_shape = (224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nnet = EfficientNetB7(input_shape=input_shape, weights='imagenet', include_top=False)\n\n# add two FC layers (with L2 regularization)\nx = net.output\nx = GlobalAveragePooling2D()(x)\n\nx = Dense(256)(x)\nx = Dense(32)(x)\n\n# Output layer\nout = Dense(num_classes, activation=\"softmax\")(x)\n\nmodel = Model(inputs=net.input, outputs=out)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## set Checkpoint : save best only, verbose on\n#checkpoint = ModelCheckpoint(\"food11_efficientnetB7.hdf5\", monitor='accuracy', verbose=0, save_best_only=True, mode='auto', save_freq=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nSTEP_SIZE_TEST =test_generator.n//test_generator.batch_size\nnum_epochs= 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Model\nhistory = model.fit_generator(train_generator,steps_per_epoch=STEP_SIZE_TRAIN,epochs=num_epochs, validation_data=valid_generator, validation_steps=STEP_SIZE_VALID) #, callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Save Model\nmodel.save('food11_efficientnetB7.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(test_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"predY=model.predict(test_generator)\ny_pred = np.argmax(predY,axis=1)\n#y_label= [labels[k] for k in y_pred]\ny_actual = test_generator.classes\ncm = confusion_matrix(y_actual, y_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_actual, y_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}