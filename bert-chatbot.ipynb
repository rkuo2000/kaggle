{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BERT finetune for Chatbot"},{"metadata":{},"cell_type":"markdown","source":"## Repro [Github](https://github.com/Macielyoung/Fine-tune-Bert-Chatbot)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/Macielyoung/Fine-tune-Bert-Chatbot\n%cd Fine-tune-Bert-Chatbot \n!mkdir model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch_pretrained_bert","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## demo.py"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, random\nfrom tqdm import tqdm\nfrom read import readPairs\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForPreTraining, BertAdam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = \"dialogue.txt\"\npairs = readPairs(corpus)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load BERT Tokenizer and Model"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"modelpath = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(modelpath)\nmodel = BertForMaskedLM.from_pretrained(modelpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transfer(pair, tokenizer):\n    # tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    # pairs = ['[CLS] do you like apple ? [SEP] ', 'i like apple so much .']\n    input_token, label_token = pair[0], pair[1]\n    input_text, label_text = tokenizer.tokenize(input_token), tokenizer.tokenize(label_token)\n\n    for word in label_text:\n        input_text.append('[MASK]')\n    #print(input_text)\n\n    for _ in range(128-len(input_text)):\n        input_text.append('[MASK]')\n    #print(input_text)\n\n    indexed_tokens = tokenizer.convert_tokens_to_ids(input_text)\n    #print(indexed_tokens)\n\n    input_tensor = torch.tensor([indexed_tokens])\n    #print(input_tensor)\n\n    loss_ids = [-1] * len(tokenizer.tokenize(input_token))\n    loss_ids += tokenizer.convert_tokens_to_ids(label_text)\n\n    loss_ids.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n    for _ in range(128-len(loss_ids)):\n        loss_ids.append(-1)\n    loss_tensors = torch.tensor([loss_ids])\n    # print(loss_tensors)\n    return [input_tensor, loss_tensors]\n\ndef process(pairs, tokenizer):\n    tensor_pairs = []\n    for pair in pairs:\n        input_text, label_text = tokenizer.tokenize(pair[0]), tokenizer.tokenize(pair[1])\n        if len(input_text) + len(label_text) < 128:\n            tensor_pair = transfer(pair, tokenizer)\n            tensor_pairs.append(tensor_pair)\n    print(\"Tokenize Trim {} Sentence Pair...\".format(len(tensor_pairs)))\n    return tensor_pairs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transfer to Tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_pairs = process(pairs, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(tensor_pairs, model, batch_size):\n    optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-3)\n    model.train()\n    for i in tqdm(range(1, 101)):\n        pair_batches = random.sample(tensor_pairs, batch_size)\n        input_batch = [tensor[0] for tensor in pair_batches]\n        label_batch = [tensor[1] for tensor in pair_batches]\n        input_tensor = torch.cat(input_batch, 0)\n        label_tensor = torch.cat(label_batch, 0)\n\n        loss = model(input_tensor, masked_lm_labels=label_tensor)\n        eveloss = loss.mean().item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        print(\"step \"+ str(i) + \" : \" + str(eveloss))\n        if i % 50 == 0:\n            torch.save(model, os.path.join(\"model/\", '{}_backup.tar'.format(i)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ntrain(tensor_pairs, model, batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Infer Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelpath = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(modelpath)\n\nmodel = torch.load(\"model/100_backup.tar\")\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question='how are you'\nwith torch.no_grad():\n    question = '[CLS] ' + question + ' [SEP] '\n    tokenized_text = tokenizer.tokenize(question)\n    # print(tokenized_text)\n    for _ in range(128-len(tokenized_text)):\n        tokenized_text.append(\"[MASK]\")\n    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n    tokens_tensor = torch.tensor([indexed_tokens])\n    predictions = model(tokens_tensor)\n    start = len(tokenizer.tokenize(question))\n    predicted_tokens = []\n    while start < len(predictions[0]):\n        predicted_index = torch.argmax(predictions[0,start]).item()\n        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n        if '[SEP]' in predicted_token or '.' in predicted_token:\n            break\n        predicted_tokens += predicted_token\n        start+=1\n    result = \" \".join(predicted_tokens)\n    print(result)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}