{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Text Generation LSTM"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import Libraries\nimport sys\nimport numpy as np\nimport random\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/textdata\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66ac8f4b65f37b45a132cd54c3af67f8cae72701"},"cell_type":"code","source":"# Load Dataset\nfilename    = '../input/textdata/shakespeare.txt'\ntext        = open(filename, encoding='utf-8').read()\ntext        = text.lower()\nprint('corpus length:', len(text))\n\n# Find all the unique characters\nchars        = sorted(list(set(text)))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))\nvocab_size   = len(chars)\n\nprint(\"List of unique characters : \\n\", chars)\nprint(\"Number of unique characters : \\n\", vocab_size)\nprint(\"Character to integer mapping : \\n\", char_indices)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing Dataset\nmax_seq_len = 40 # cut text in semi-redundant sequences of max_seq_len characters\nstep = 3 \nsentences = [] # list_X\nnext_chars= [] # list_Y\n\nfor i in range(0, len(text) - max_seq_len, step):\n    sentences.append(text[i: i + max_seq_len])\n    next_chars.append(text[i + max_seq_len])\nprint('nb sequences:', len(sentences))\n\nnum_sequences  = len(sentences)\nprint(\"Number of sequences: \", num_sequences)\nprint(sentences[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Vectorization...')\ntrain_X = np.zeros((len(sentences), max_seq_len, len(chars)), dtype=np.bool)\ntrain_Y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        train_X[i, t, char_indices[char]] = 1\n    train_Y[i, char_indices[next_chars[i]]] = 1\n\nprint(train_X.shape)\nprint(train_Y.shape)\nprint(max_seq_len, vocab_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\ninput_shape = (max_seq_len, vocab_size)\n\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=input_shape))\nmodel.add(Dense(len(chars), activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile Model\nadam = Adam(lr=0.0005)\nmodel.compile(optimizer=adam, loss='mse')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{"trusted":true,"_uuid":"26bdbaee4235f5d035efd3dce0da6e639cd2ce66"},"cell_type":"code","source":"# Train Model\nnum_epochs = 10\nbatch_size = 128\n#model_path = \"textgen-lstm.h5\"\n#checkpoint = ModelCheckpoint(model_path, monitor='loss', save_best_only=True, verbose=1, mode='min')\n#callbacks_list = [checkpoint]\n\nmodel.fit(train_X, train_Y, epochs = num_epochs, batch_size = batch_size, verbose=1) #, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate Text"},{"metadata":{"trusted":true,"_uuid":"708eb95f9f22cd304877580d9f8d9c54c2b28062"},"cell_type":"code","source":"# Generate Text\ndef sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text():\n    start_index = random.randint(0, len(text) - max_seq_len - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print('----- diversity:', diversity)\n        generated = ''\n        sentence = text[start_index: start_index + max_seq_len]\n        generated += sentence\n        print('----- Generating with seed: \"' + sentence + '\"')\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred = np.zeros((1, max_seq_len, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            sentence = sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()\n\ngenerate_text()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}